{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The [SMS Spam Collection v.1](http://dcomp.sor.ufscar.br/talmeida/smspamcollection/) is a public set of SMS labeled messages that have been collected for mobile phone spam research. It has one collection composed by 5,574 English, real and non-enconded messages, tagged according being legitimate (ham) or spam. \n",
    "\n",
    "Some questions arise when we take a look at the data set are:\n",
    "- Is there any pattern that could help us classify each message as ham or spam at a first view?\n",
    "- Which are the most common and most significant words for ham and spam messages?\n",
    "- How well our model predicts a new message as ham or spam?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\MyPc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MyPc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\MyPc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data set\n",
    "sms = pd.read_csv('SMSSpamCollection.txt', sep='\\t', names=['label', 'text'])\n",
    "sms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      "label    5572 non-null object\n",
      "text     5572 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.1+ KB\n"
     ]
    }
   ],
   "source": [
    "sms.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                    text\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of ham messages in the dataset is 4825\n",
      "The number of spam messages in the dataset is 747\n"
     ]
    }
   ],
   "source": [
    "print('The number of ham messages in the dataset is {}'.format(sms['label'].value_counts()[0]))\n",
    "print('The number of spam messages in the dataset is {}'.format(sms['label'].value_counts()[1]))      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the dataset is unbalanced. This could affect our model prediction and the accuracy. Lets move on..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  text_length\n",
       "0   ham  Go until jurong point, crazy.. Available only ...          111\n",
       "1   ham                      Ok lar... Joking wif u oni...           29\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...          155\n",
       "3   ham  U dun say so early hor... U c already then say...           49\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...           61"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms['text_length'] = sms['text'].apply(lambda col: len(col))\n",
    "sms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825.0</td>\n",
       "      <td>71.482487</td>\n",
       "      <td>58.440652</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>910.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747.0</td>\n",
       "      <td>138.670683</td>\n",
       "      <td>28.873603</td>\n",
       "      <td>13.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>223.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count        mean        std   min    25%    50%    75%    max\n",
       "label                                                                 \n",
       "ham    4825.0   71.482487  58.440652   2.0   33.0   52.0   93.0  910.0\n",
       "spam    747.0  138.670683  28.873603  13.0  133.0  149.0  157.0  223.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.groupby('label')['text_length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtYAAAF/CAYAAABt6459AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de3hdZZn38W/S9JDaUnpAinIqCrcFRKUoyEhBRRFExdMMeoGKR0Z8tR4GUBAZRH3Li6CMoIIiyngGdIQRRAS1VpShglINdwWx2qEVKAUKbdJT3j/WSgkhSXfStZPs9Pu5rlzde61nrXXvvR/Ibz951lpNnZ2dSJIkSdo6zcNdgCRJkjQaGKwlSZKkChisJUmSpAoYrCVJkqQKGKwlSZKkChisJUmSpAq0DHcBkkaOiNgduBu4o1zUDDwKfC4zv1e2OQu4KzO/0c9+zgB+n5n/1cu6zdtHRCewQ2Y+MIAanw+8IzNPjIgDgFMz8w21bj8YETEGuAqYDVyQmV/otu4yYHFmnluH425+H7f2OBGxC3AtsAH418y8eZD7edJnFhFvA96QmUcPZp/1FhEfAfbNzLf1su6VwOnARIrfiX8EPpSZy4a4xrHAp4BXAJ1AE/Ad4DOZ2Vl+/m8FXpKZN3XbbnfgL8BFmfm+Le1n6F6RtG0yWEvqaW1mPrfrSUTsBvwsIjZm5pWZeUYN+3gJ8KfeVtS4fX/2AXYu93UrUNdQXXo6cATwlMzcOATH69Ln+zgILwZWZObhFe2v4UXE04CvA3Myc2m57DTge8DBQ1zOPGAPYP/M3BARU4AbgQeAi8s2fwOOB27qtt1bgPsGuB9JdWKwltSvzFxajpz+G3Bl95HTiPh34LXAOmAl8DbgdcABwP+LiI3Aa4BpwDOAa4AdeeLI66fKUehm4PTMvKbnCGjXc+BfgbOAKRHxNYpQ9IXM3LcMEBcCz6UYqbsW+FgZLtqB/wu8HNgJOCczv9jztUbEIcD/oxi9XEcxkrkQuA4YCyyKiNdn5t29vVcRMRv4PDAdGEMxun1pRBxGMYr4F2Dfcl/vycyFEbED8LXy/VkJrAAWA/f3eB8BDo6IX3e9h8CbM/Ox3j6HzFzera4XA2eX79tNmfniiHg38H5gI/AP4H2ZuaT8fDd/Xpl5Sm+vtS8RsRfF5zCZ4r2+HfiXzGwvP4fzgMOBScCZwBuBZwP3Aq/KzMcGuL8nfa7lqO0FwMsoQuc/gId7KXcGMK6spcvngN+Xx35bWV8zsBvwv8BbM/PeiDgIOAcYXx77p5n5jnIE+Ubgp8Acit+zZwDvAZ4F3Aq8KTM39ahlJ4p+MR7YkJkPR8TxPHHK5neAd0REa2auLZf9C8UXgeYB7EdSnfgfmqRa/J4i/GxWTi2YBzw/Mw8ArgcOzMwLKcLDv2XmD8rmEzNznz5C2l8yc3/gOODrZdDsVWb+nSKkLMjME3qsvoAiVD6bIpA+B/hIuW488EBmHkwR0M+PiAk9Xs904ArgA5m5H8Wf3f+TInwdRTmS30+obim3PzUz5wCHAh8pAxjAgcBnM/N5FEH6093q/mNmzqYIcQeXr7W39/HpFKF0L4pR+9f19Tn0eN9u6va+vTgiXgKcDLw4M58DfAv4YUQ0lZv093kB3BQRt3f9UHzZ6fIu4OuZeRDwTGAW8Mpy3XiKUfMXUHwp+kpZ+97AFIovYT1taX+9fa7vLd+jvSnC9a69vYjM/ANwCXBbRPwpIi4BXkXxRarLoRR9Ym9gEcXnBfAB4IzMPLA8zqsjYk65bhbw3+XncTPFl603Ufy15RDgIJ7sPIrP94GI+HlEfAoYn5mLu7W5v9zfqwEi4kVAG/DgAPcjqU4M1pJq0Qms6bHsfykC9+8i4lzg9sz8YR/b/6qffX8JoPzF/yfghYOs8UiK0evOzOwo93tkt/Vd871/RxHIntJj+wMp5n7/tqznjxSj1YfVePy9KEZ5Ly3D5i+AVuB55fqlmXl7txqmlY+PovwTfTnKfEU/x/hhZq4pp6MsBp7KwD6HLq8AvpuZ95fHvYwijO1eru/v84IikD+364citHc5Bbg/Ik4Gvgg8jSeOCF9Z/ns3cEdm/m85ensPj78n3W1pf719rocD38rMdeUI+Df7eiGZ+WGKUd6PA2sp/mLxi3JePcD1mbmkfHwJxZQgKL54bR8RHwMuovisu+paD1zd7XX+OjMfycx2ipH5J73OzFxWBvE5wPeBAG6OiPf2aPoNii+hXTVcNsj9SKoDg7WkWjyfx09oBKAMQ4dSTP9YSTFaeE4f2z/az767z1lupgglXSdddRlXQ43N5Xbdn4/t9nxtWXdXm+77h2LqRs+Tu3ruoz9jgId7BM6DKEanNx+/1P31behRS39zuNf33McAP4futfZ8rU08/lr7+7y25NvAu4GlwPkUgbf76+vo9rj76xns/vr6XLu32dDbjiPi1RFxQmauLM8feD/FCar78PgXou7bNvP45/NLii9Fd1KM2P9vt2Ou63Gi4BZfZ0ScExF7ZeafMvPC8oTcd1KMvnf3I+DA8i8Vc3ni6PpA9iOpDgzWkvpVznH9OPDZHsufQzFq2paZn6EIPc8vV2+g9kD6tnJ/+1P8qf+3FH/y3jciJpTzZbufoNjXvn8CvC8imiJiPEUY+2mNNUDxJ/ZnRcQLynr2oQguP69x+wTWRsRx5fa7ULw/c/rdCv4beEe5zXSKudJdoWyL7+MWPoe+XAcc2zXtJiJOoAjld21hu1ocAZyVmd8tnx9IEeSHcn/XAm8p+88EinnIvVkNfCYi9u62bA+K971rys9LI+Lp5eMTgasjYnuK9/iUzLyKYlrOM2uoqz9PBT4ZERMBymk5+1J8kdis/GvMDyhGrq/OzJ5fGmraj6T6MFhL6qm12/zZ31H8qfmjmfnf3Rtl5u8pTpq6NSJuBd4OfKhc/SOKwPLWGo63R0TcRjHf9tjMfJBinvAvKEYDf0kx17jLb8ptruqxn/dThIo7yp+kOGGwJllcPu6NwH9ExB0U845P6DYNYEvbr6OYI/zOiPhD+Ro+npkLt7DpBykC/R0U0ySW8vi0my2+j1v4HPra5qcUAfzGiPgjxZSCo3s5oW4wPgb8oHw9X6b4HJ85xPv7MkWfWVy2v6e3RuXc8/dRzO3/c0S0UZy8eFRmriqbLQMuL9ftDszLzIeAz1BMv1kMnEoxbWhrXud7KaaJ/KH8TO6kmHd+Ui9tv0ExRemyrdyPpIo1dXZ6WUtJGi7l3NfbMvPmcqR9AfCJzLx2mEvb5vW8Oo0kbYmX25Ok4fUnilHyMRRzyb9vqJakxuSItSRJklQB51hLkiRJFTBYS5IkSRUwWEuSJEkVGBUnL95+++2d48ePH/LjdnR0MBzH1chmv1Bv7Bfqjf1CvbFfjGxr1qx5YM6cOTv0tm5UBOvx48cze/bsIT9uW1vbsBxXI5v9Qr2xX6g39gv1xn4xsi1atGhpX+ucCiJJkiRVwGAtSZIkVcBgLUmSJFVgVMyxliRJ2tatX7+eZcuW0d7ePtyljAoTJkxg5513ZuzYsTVvY7CWJEkaBZYtW8bkyZPZfffdaWpqGu5yGlpnZycrV65k2bJlzJo1q+btnAoiSZI0CrS3tzN9+nRDdQWampqYPn36gEf/DdaSJEmjhKG6OoN5L50KIkmSNAo9vGYdqzs2VLa/yeNbmDJxXJ/rf/vb3/Kd73yH888/f/Oyc889lz322IPXve51W338TZs2MX/+fJYsWUJzczNjx47ltNNOY5dddtnqfVfFYC1JkjQKre7YwC+XPFDZ/ubuNaPfYF1vCxYs4L777uNrX/saADfccAOf/vSn+eIXvzhsNfVksJYkSVJdbdy4kTPOOIMVK1awatUq5s6dy7x58zj11FNpaWnh3nvvZd26dRx11FHcdNNNLF++nIsuuohdd9118z5mzpzJ4sWL+fGPf8xBBx3ES1/6UubOnQvAq171Kg444ACWLFnCrFmzmD59Orfeeivjxo3j4osv5g9/+APz58+npaWF7bbbjnPPPZdJkyZV/jqdYy1JkqRK/OY3v+H444/f/HPNNdcAsHz5cp773Ofy1a9+lW9/+9t8+9vf3rzN05/+dC699FL22GMPli1bxiWXXMLLX/5ybrzxxifsOyL45Cc/yQ033MDRRx/N61//em6//XYAHnvsMY4++mi++c1vcuutt7L//vvzzW9+k/Xr13PXXXdxww038LKXvYz//M//5A1veAOPPPJIXV6/I9aSJEmqxEEHHfSkOdYA22+/PXfccQe/+c1vmDRpEuvWrdvcZu+99wZgu+22Y4899tj8uHsbgDvvvJNZs2Zx3nnn0dnZycKFC5k3bx4LFy4EYJ999tm87TOe8YzNjzs6OjjxxBP50pe+xFvf+lZ23HFH9ttvv7q8fkesJUmSVFdXXXUVkydP5rOf/Sxvf/vbaW9vp7OzE6j96hs333wz5513Hhs3bqSpqYk999yT1tbWzdv3t5+rr76a1772tVx++eXsueeefO9739v6F9ULR6yH2EDP0N3SGbiSJEkj3Qtf+EI+9KEPsWjRIlpbW9ltt9247777BrSP448/nvnz53PMMccwadIkmpubOeecc2ra9tnPfjannnoqEydOZOzYsZx11lmDeRlb1NT1baGRtbW1dc6ePXs4jstAj7ts1ZoBnaE7d68Z7Dx14kBL0zAaTL/Q6Ge/UG/sF+rNYPtFz+2G+nJ7o1Fvn8WiRYsWzZkz54De2jtiLUmSNApNmThumwvCw8051pIkSVIFDNaSJElSBQzWkiRJUgUM1pIkSVIFDNaSJElSBep2VZCIOBCYn5mHdVv2ZuD/ZOYLy+fvAt4DbADOzsxrImIG8C2gFbgXOCEz19SrTkmSpFFp1Sqo8tbd220HU6f22+Tiiy/m17/+Nc3NzTQ1NfHBD36Qfffdt7oaeti0aRPz589nyZIlNDc3M3bsWE477TR22WWXuh2zP3UJ1hFxMnA88Fi3Zc8F3gE0lc9nAu8HDgAmAL+KiJ8CZwDfyszLIuJUiuB9PpIkSardI4/AT35S3f6OOKLfYH3XXXdx44038u1vf5umpiba2to45ZRT+NGPflRdDT0sWLCA++67j6997WsA3HDDDXz605/mi1/8Yt2O2Z96jVjfDbwOuBwgIqYD/xeYB1xStnkBsDAzO4COiLgL2A94EfDpss215WODtSRJ0gg2bdo07r33Xq644grmzp3L7NmzueKKK4DiromzZs3innvuobOzk/PPP59p06ZxxhlnsGLFClatWsXcuXOZN28ep556Ki0tLdx7772sW7eOo446iptuuonly5dz0UUXseuuu24+5syZM1m8eDE//vGPOeigg3jpS1/K3LlzAXjVq17FAQccwJIlS5g1axbTp0/n1ltvZdy4cVx88cX84Q9/YP78+bS0tLDddttx7rnnMmnSpK16D+oSrDPzyojYHSAixgBfBT4IrO3WbDvg4W7PVwNTeizvWtavjo4O2tratr7wAWpvbx/wcde1TGL5iuU1t185rYnVK5YOtDQNo8H0C41+9gv1xn6h3gy2X6xfv561ax+PWi3r19O5bl1ldTWtX8+GtWv7XN/a2srnPvc5vvOd7/CFL3yBCRMm8L73vY/DDz+cjRs3su+++/LRj36U7373u1x44YUcd9xx7L333px++ul0dHRwxBFH8J73vIcNGzbwtKc9jdNOO42zzz6bv/71r1xwwQVcdNFF/OQnP+G4447bfMxdd92Vj3/841x55ZV88pOfZMcdd+TDH/4wBxxwAKtXr+ZlL3sZJ598Mscccwwf/vCHOfHEE3nHO97B4sWLue666zjssMN461vfys9//nPuu+8+xowZ86T3dCCfxVDceXEOsCfwRYopH3tHxOeAG4HJ3dpNBh4CHikfr+22rF/jx48fllvCDvaW5jvNrP028tNnTGfnqcMzT0iD4y2K1Rv7hXpjv1BvtuaW5q2trY8vGDsWxlV458WxYxnbff89LF26lOnTp3POOecAcMcdd/Dud7+bQw45hDFjxjB37lxaW1s58MADWbBgATNnziQzOf3005k0aRLr1q2jtbWVlpYWnvOc59Da2srUqVPZY489aG1tZfr06ZvbdLnzzjuJCD7/+c/T2dnJwoULOfnkk1m4cCHNzc3sv//+TJgwgSlTprD33nvT2trK9ttvT1NTE+973/v40pe+xIknnsiOO+7I85///Ce+f8DYsWN7u6V5n+9B3a8Kkpm3ZOY+5UmMxwJ/ysx5wC3AIRExISKmALOBxcBC4Khy8yOBBfWuUZIkSVsnMznzzDPp6OgAYNasWUyePHnzKPDixYsB+N3vfsczn/lMrrrqKiZPnsxnP/tZ3v72t9Pe3k5nZzH42NTUVNMxb775Zs477zw2btxIU1MTe+65J62trZu3728/V199Na997Wu5/PLL2XPPPfne97436NfeZShGrHuVmSsi4gKK4NwMnJaZ7RFxNvD18oohDwBvHq4aJUmSVJuXv/zl3H333bzxjW9k4sSJdHZ2cvLJJzN5cjFB4Qc/+AGXXXYZra2tnHPOOTzwwAN86EMfYtGiRbS2trLbbrtx3333DeiYxx9/PPPnz+eYY45h0qRJNDc3bx4x35JnP/vZnHrqqUycOJGxY8dy1llnDfg199TU9c2gkbW1tXU20lSQXy55oOb2c/eawc5TJw60NA0j/7Sr3tgv1Bv7hXqzNVNBnrDdMFxury/HH388Z555Js94xjOqq2cI9PZZLFq0aNGcOXMO6K39sI1YS5IkqY6mTh10ENbgGKwlSZJUV5dffvlwlzAkvKW5JEmSVAGDtSRJ0igxGs6dGykG814arCVJkkaBCRMmsHLlSsN1BTo7O1m5ciUTJkwY0HbOsZYkSRoFdt55Z5YtW8b9998/3KWMChMmTGDnnXce0DYGa0mSpFFg7NixzJo1a7jL2KY5FUSSJEmqgMFakiRJqoDBWpIkSaqAwVqSJEmqgMFakiRJqoDBWpIkSaqAwVqSJEmqgMFakiRJqoDBWpIkSaqAwVqSJEmqgMFakiRJqoDBWpIkSaqAwVqSJEmqgMFakiRJqoDBWpIkSaqAwVqSJEmqgMFakiRJqoDBWpIkSaqAwVqSJEmqgMFakiRJqoDBWpIkSaqAwVqSJEmqgMFakiRJqoDBWpIkSaqAwVqSJEmqgMFakiRJqoDBWpIkSaqAwVqSJEmqQEu9dhwRBwLzM/OwiHgu8B/ARqADeEtm/iMi3gW8B9gAnJ2Z10TEDOBbQCtwL3BCZq6pV52SJElSFeoyYh0RJwNfASaUiz4P/J/MPAy4CjglImYC7wf+CTgC+ExEjAfOAL6VmYcAt1EEb0mSJGlEq9dUkLuB13V7fmxm3l4+bgHagRcACzOzIzMfBu4C9gNeBFxXtr0WOLxONUqSJEmVqctUkMy8MiJ27/Z8OUBEHAy8D5hLMUr9cLfNVgNTgO26Le9a1q+Ojg7a2toqqX0g2tvbB3zcdS2TWL5iec3tV05rYvWKpQMtTcNoMP1Co5/9Qr2xX6g39ovGVbc51j1FxL8ApwGvzMz7I+IRYHK3JpOBh4Cu5Wu7LevX+PHjmT17dvVFb0FbW9uAj7ts1Rp2mtlZc/vpM6az89RdBlqahtFg+oVGP/uFemO/UG/sFyPbokWL+lw3JFcFiYjjKEaqD8vMv5SLbwEOiYgJETEFmA0sBhYCR5VtjgQWDEWNkiRJ0taoe7COiDHABRSjz1dFxM8j4t8zc0W5fAFwI3BaZrYDZwPHRsRC4IXAF+pdoyRJkrS16jYVJDP/ChxUPp3WR5tLgEt6LPsH8Ip61SVJkiTVgzeIkSRJkipgsJYkSZIqYLCWJEmSKmCwliRJkipgsJYkSZIqYLCWJEmSKmCwliRJkipgsJYkSZIqYLCWJEmSKmCwliRJkipgsJYkSZIqYLCWJEmSKmCwliRJkipgsJYkSZIqYLCWJEmSKmCwliRJkipgsJYkSZIqYLCWJEmSKmCwliRJkipgsJYkSZIqYLCWJEmSKmCwliRJkipgsJYkSZIqYLCWJEmSKmCwliRJkipgsJYkSZIqYLCWJEmSKmCwliRJkipgsJYkSZIqYLCWJEmSKmCwliRJkipgsJYkSZIqYLCWJEmSKmCwliRJkipgsJYkSZIq0FKvHUfEgcD8zDwsIp4JXAZ0AouBkzJzU0R8AnglsAGYl5m39NW2XnVKkiRJVajLiHVEnAx8BZhQLjoPOD0zDwGagNdExP7AocCBwLHAhX21rUeNkiRJUpXqNRXkbuB13Z7PAX5RPr4WOBx4EXB9ZnZm5t+AlojYoY+2kiRJ0ohWl6kgmXllROzebVFTZnaWj1cDU4DtgJXd2nQt761tvzo6Omhra9vqugeqvb19wMdd1zKJ5SuW19x+5bQmVq9YOtDSNIwG0y80+tkv1Bv7hXpjv2hcdZtj3UP3OdKTgYeAR8rHPZf31rZf48ePZ/bs2RWUOTBtbW0DPu6yVWvYaWbnlhuWps+Yzs5TdxloaRpGg+kXGv3sF+qN/UK9sV+MbIsWLepz3VBdFeS2iDisfHwksABYCBwREc0RsSvQnJkP9NFWkiRJGtGGasT6w8AlETEOaAOuyMyNEbEAuJki4J/UV9shqnFE2rBxE8tWram5/eTxLUyZOK6OFUmSJKk3AwrWEbFLZv69lraZ+VfgoPLxEoorgPRscyZwZo9lvbbdVq1dv4nb7n6w5vZz95phsJYkSRoGWwzWEfF+YC2wPXBCRFyXmR+qe2WSJElSA6llxPpNFCPI1wH7AD+ra0WSJElSA6rl5MVOYCfgH+Vl8KbVtyRJkiSp8dQyYn0T8EvgTRFxPnBlfUuSJEmSGs8Wg3VmngacFhFTgVMyc139y5IkSZIaSy0nL84FLgLGAN+PiKWZ+dW6VyZJkiQ1kFrmWJ8NzAVWAJ8G3lvXiiRJkqQGVEuw3pSZDwKdmdkOrK5zTZIkSVLDqSVY3xURnwGmR8SpwNI61yRJkiQ1nFqC9YkUYfpXwKPAO+takSRJktSAagnWbwbWAL8FHgHeEBEvqmtVkiRJUoOp5TrWxwITgZuBFwATgA0R8bvM/GA9i5MkSZIaRS0j1mOBl2TmR4GXAasz81DgwLpWJkmSJDWQWoL1dIpwTflv1y3Nx9elIkmSJKkB1TIV5ELgDxHxR+BZwDkR8THgurpWJkmSJDWQWm5p/tWI+CHwTOCuzFwZEWMyc2P9y5MkSZIaQy23ND8IOIFiGkhTRDwtM4+oe2WSJElSA6lljvUFwM+BKRTXs36gngVJkiRJjaiWYP1QZn4beCQzzwR2rm9JkiRJUuOpJVh3RsQ+wMSICGBmnWuSJEmSGk4twfpDwD4UU0K+BXyprhVJkiRJDaiWq4L8MSLagCbgg8Bv6l6VJEmS1GBquSrIfOAvwG7A/sA/gLfWuS5JkiSpodQyFeRFmfll4IWZ+Qo8eVGSJEl6klqC9ZiIeAHw14gYB+xQ55okSZKkhlPLLc2/AfwH8HbgHODzda1IkiRJakC1nLx4EXARQER8NjP/XveqJEmSpAZTy8mL7wfWAtsDJ0TEdZn5obpXJkmSJDWQWqaCvAk4FLiO4nrWP6trRZIkSVIDqunOi8BOwD8ysxOYVt+SJEmSpMZTy4j1TcAvgTdFxPnAlfUtSZIkSWo8tZy8eBpwWkRMBU7JzHX1L0uSJElqLLWcvDiX4qogY4DvR8TSzPxq3SuTJEmSGkgtc6zPBuYCK4BPA++ta0WSJElSA6olWG/KzAeBzsxsB1bXuSZJkiSp4dRy8uJdEfEZYHpEnAosHcyBImIs8HVgd2Aj8C5gA3AZxZVHFgMnZeamiPgE8Mpy/bzMvGUwx5QkSZKGSi0j1idShOlfAY9SBOLBOApoycyDgbOATwHnAadn5iFAE/CaiNif4rrZBwLHAhcO8niSJEnSkOlzxLo8abHLn8ofgIMoLr83UEuAlohoBrYD1pf7+kW5/lrg5UAC15fXzP5bRLRExA6ZeX9fO+7o6KCtrW0QJW2d9vb2AR93Xcsklq9YXnP7Z80YN6D2K6c1sXrFoP6ooIoMpl9o9LNfqDf2C/XGftG4+psK8nPgbuB/yudN5b+dDC5YP0oxDeROYAZwNDC3DNBQzN2eQhG6V3bbrmt5n8F6/PjxzJ49exAlbZ22trYBH3fZqjXsNLNzyw1LrRMnstPMnWpuP33GdHaeusuAalK1BtMvNPrZL9Qb+4V6Y78Y2RYtWtTnuv6C9QHAm4H9gRuBb2bmPVtRxweBn2TmRyNil3Kf47qtnww8BDxSPu65XJIkSRqx+pxjnZm/y8yPAC8FbgZOj4j/joj3DPJYq4CHy8cPAmOB2yLisHLZkcACYCFwREQ0R8SuQHNmPjDIY0qSJElDYosnL5ZTNX4N3FC2f+cgj3U+sH9ELKAYrf4YcBLw7xFxM8Xo9RWZuYgiYN9Mcfv0kwZ5PEmSJGnI9Hfy4liKUeQ3A3sBPwI+kJlLBnOgzHwU+OdeVh3aS9szgTMHcxxJkiRpOPQ3Yn0f8BmK60t/lGLUeveIePlQFCZJkiQ1kv5OXvwviiuAPKP86dIJXF/PoiRJkqRG02ewzsy3DWEdkiRJUkOr5c6LkiRJkragz2AdEVOGshBJkiSpkfU3Yn01QER8cYhqkSRJkhpWfycvro2I/wH2jIjnlMuagM7MPLj+pUmSJEmNo79gfSTwNODLwL9ShGpJkiRJvejvqiCbgGUR8Rrg3cA+wBLAqSGSJElSD7VcFeTLwDOBnwK7A1+pZ0GSJElSI+pvKkiXPTNzbvn4hxHx63oWJEmSJDWiWkasJ0TERICIaAXG1LckSZIkqfHUMmL9eeD3EbEY2Bv4RH1LkiRJkhrPFoN1Zn4zIq4F9gDuycyV9S9LkiRJaiy1jFiTmQ8CD9a5FkmSJKlh1TLHWpIkSdIWbDFYR8RHhqIQSZIkqZHVMmJ9VER4JRBJkiSpH7XMsZ4B3BsR9wCdQGdmHlzfsiRJkqTGUkuwflXdq5AkSZIaXC3BegMwH9gBuAL4A7C0nkVJkiRJjaaWOdYXA5cC44BfUtwwRpIkSVI3NTYf1ZUAABLLSURBVN3SPDNvpJhbnUB7nWuSJEmSGk4twbojIo4AxkTEQRisJUmSpCepJVi/GziB4uogHwH+ta4VSZIkSQ1oiycvZuayiPg0sBewODPvqX9ZkiRJUmOp5c6LpwMXAf8EfDUi5tW9KkmSJKnB1HTnRWBuZn4QOBQ4tr4lSZIkSY2nlmB9HzCxfDwOuL9+5UiSJEmNqc851hFxM8UtzJ8K/Dkifg/sDawcotokSZKkhtHfyYtO+ZAkSZJq1GewzsylABHxAoqQPaHb6vfWuS5JkiSpoWzxcnvA14H5wKo61yJJkiQ1rFqC9Z8z87J6FyJJkiQ1slqC9ZUR8R3gT10LMvOswRwsIj4KvJri6iIXAb8ALqM4SXIxcFJmboqITwCvBDYA8zLzlsEcT5IkSRoqtVxu773AbcA/uv0MWEQcBhxMcaOZQ4FdgPOA0zPzEKAJeE1E7F+uP5BibveFgzmeJEmSNJRqGbF+MDPnV3CsI4A7gB8A2wH/BryLYtQa4Frg5UAC12dmJ/C3iGiJiB0y0+tnS5IkacSqJVg/EBFfBn5HMWWDzLx4EMeaAewGHA3MAn4ENJcBGmA1MIUidHe/VnbX8j6DdUdHB21tbYMoaeu0t7cP+LjrWiaxfMXymts/a8a4AbVfOa2J1SuWDqgmVWsw/UKjn/1CvbFfqDf2i8ZVS7C+q/x35lYeayVwZ2auAzIi2immg3SZDDwEPFI+7rm8T+PHj2f27NlbWd7AtbW1Dfi4y1atYaeZnVtuWGqdOJGdZu5Uc/vpM6az89RdttxQdTOYfqHRz36h3tgv1Bv7xci2aNGiPtfVEqy/VlEdvwI+EBHnATsBTwF+FhGHZebPgSOBmyiC/DkRcS6wM8Wo9gMV1SBJkiTVRS3B+rsUU0CaKaZw/Bl40UAPlJnXRMRc4JZyXycB9wCXRMQ4oA24IjM3RsQC4OZu7VSjDRs3sWzVmgFtM3l8C1MmjqtTRZIkSduGLQbrzHxh1+OI2B748mAPlpkn97L40F7anQmcOdjjbMvWrt/EbXc/OKBt5u41w2AtSZK0lWq53F53DwPPqEchkiRJUiPb4oh1RNxMMRWkCdgBuKHeRUmSJEmNppY51sd2e9yemYO6QYwkSZI0mvUZrCPiLX0sJzO/Ub+SJEmSpMbT34h1zwsoNgEnAGsAg7UkSZLUTZ/BOjM/2vU4Ip4JXAZcA8yrf1mSJElSY6nl5MWTKML0BzPzmvqXJEmSJDWe/uZYP53irosPAi/IzFVDVpUkSZLUYPobsV4MrANuBC6MiM0rMvPNda5LkiRJaij9BetjhqwKSZIkqcH1d/LiL4ayEEmSJKmRDfSW5pIkSZJ6YbCWJEmSKmCwliRJkipgsJYkSZIqYLCWJEmSKmCwliRJkipgsJYkSZIqYLCWJEmSKmCwliRJkipgsJYkSZIqYLCWJEmSKmCwliRJkipgsJYkSZIqYLCWJEmSKmCwliRJkipgsJYkSZIqYLCWJEmSKmCwliRJkipgsJYkSZIqYLCWJEmSKmCwliRJkirQMtwFaPht2LiJZavW1Nx+8vgWpkwcV8eKJEmSGo/BWqxdv4nb7n6w5vZz95phsJYkSerBqSCSJElSBYZ8xDoingosAl4GbAAuAzqBxcBJmbkpIj4BvLJcPy8zbxnqOiVJkqSBGNIR64gYC3wZWFsuOg84PTMPAZqA10TE/sChwIHAscCFQ1mjJEmSNBhDPRXkXOBLwL3l8znAL8rH1wKHAy8Crs/Mzsz8G9ASETsMcZ2SJEnSgAzZVJCIeBtwf2b+JCI+Wi5uyszO8vFqYAqwHbCy26Zdy+/va98dHR20tbVVX/QWtLe3D/i461omsXzF8prbP2vGuLq2H8w2K6c1sXrF0gEdY1symH6h0c9+od7YL9Qb+0XjGso51m8HOiPicOC5wDeAp3ZbPxl4CHikfNxzeZ/Gjx/P7Nmzq622Bm1tbQM+7rJVa9hpZueWG5ZaJ05kp5k71a39YLaZPmM6O0/dZUDH2JYMpl9o9LNfqDf2C/XGfjGyLVq0qM91QzYVJDPnZuahmXkYcDvwFuDaiDisbHIksABYCBwREc0RsSvQnJkPDFWdkiRJ0mAM93WsPwxcEhHjgDbgiszcGBELgJspgv9Jw1mgJEmSVIthCdblqHWXQ3tZfyZw5hCVI0mSJG01bxAjSZIkVcBgLUmSJFXAYC1JkiRVwGAtSZIkVcBgLUmSJFXAYC1JkiRVwGAtSZIkVcBgLUmSJFXAYC1JkiRVwGAtSZIkVcBgLUmSJFXAYC1JkiRVwGAtSZIkVcBgLUmSJFXAYC1JkiRVwGAtSZIkVcBgLUmSJFXAYC1JkiRVwGAtSZIkVcBgLUmSJFWgZbgLkLbWw2vWsbpjQ83tJ49vYcrEcXWsSJIkbYsM1mp4qzs28MslD9Tcfu5eMwzWkiSpck4FkSRJkipgsJYkSZIqYLCWJEmSKuAca9WdJxdKkqRtgcFaA7Zh4yaWrVpTc/uO9Rv57T2ram7vyYWSJKkRGaw1YGvXb+K2ux+suf3zdt2+jtVIkiSNDM6xliRJkipgsJYkSZIqYLCWJEmSKmCwliRJkipgsJYkSZIqYLCWJEmSKuDl9jTiDOY62ZIkScNtyIJ1RIwFLgV2B8YDZwN/Ai4DOoHFwEmZuSkiPgG8EtgAzMvMW4aqTg0/r5MtSZIa0VBOBTkOWJmZhwBHAl8AzgNOL5c1Aa+JiP2BQ4EDgWOBC4ewRkmSJGlQhjJYfx/4eLfnG4A5wC/K59cChwMvAq7PzM7M/BvQEhE7DGGdkiRJ0oAN2VSQzHwUICImA1cApwPnZmZn2WQ1MAXYDljZbdOu5ff3te+Ojg7a2trqUXa/2tvbB3zcdS2TWL5iec3tnzVjXF3bD8UxRlr7ldOaWL1iac3tB2ow/UKjn/1CvbFfqDf2i8Y1pCcvRsQuwA+AizLzWxFxTrfVk4GHgEfKxz2X92n8+PHMnj276nK3qK2tbcDHXbZqDTvN7Nxyw1LrxInsNHOnurUfimOMtPbTZ0xn56m71Nx+oAbTLzT62S/UG/uFemO/GNkWLVrU57ohmwoSETsC1wOnZOal5eLbIuKw8vGRwAJgIXBERDRHxK5Ac2Y+MFR1SpIkSYMxlCPWHwOmAh+PiK651h8ALoiIcUAbcEVmboyIBcDNFMH/pCGsUZIkSRqUoZxj/QGKIN3Tob20PRM4s84lSZIkSZXxzouSJElSBQzWkiRJUgUM1pIkSVIFhvRye6PRw2vWsbpjQ83tO9ZvrGM1kiRJGi4G6620umMDv1xS+9UAn7fr9nWsRpIkScPFqSCSJElSBQzWkiRJUgWcCqJRa8+x62ltfwyAtROewp/Xjx3miiRJ0mhmsNao1dr+GI9d/WMAnvKqo2CM89slSVL9OBVEkiRJqoDBWpIkSaqAwVqSJEmqgMFakiRJqoDBWpIkSaqAwVqSJEmqgJfb06jS/drV08Zs4rFhrkeSJG07DNYaVbpfu/qpR790mKuRJEnbEqeCSJIkSRUwWEuSJEkVMFhLkiRJFTBYS5IkSRUwWEuSJEkVMFhLkiRJFfBye9omTBvXxH7rHgLgKY+Nh6kTh7kiSZI02jhirW1CS0c7j139Yx67+seMeXT1cJcjSZJGIUes1bC67rI4tcNuLEmShp+JRA2r6y6LM497HTCh5u02dXaybNWaAR1r8vgWpkwcN8AKJUnStsRgrYY3gU3st7GYPz1tzCYe20L7DZs6+eWSBwZ0jLl7zTBYS5KkfhmsNeJ1TfkAmDRpAo8+2g48HqKb1q7hsauvB+CpR790uMqUJEnbOIO1RryuKR9QBOd/XPOzzY8lSZJGCq8KIkmSJFXAYC1JkiRVwKkgGpG6z6uu5YTEetuwcVPNVxJZ1zKJh9es82RHSZK2MQZrDYuu4Lx2wlP48/qxT1rfc171cFu7fhO33f1gTW2Xr1jOv8yYbrCWJGkbY7DWsOgKzk951VEwZvvhLmfYPbxmHas7NtTc3utqS5I08ozIYB0RzcBFwHOADuCdmXnX8Fal3vQ28tx9GsfaCU95Ult4fHrHtHFN7LeuuAZ116X0dniwnXUjYPrH1hjI1BGAjvUb+e09q2puf/AzptU9iBv2JUkamBEZrIFjgAmZ+cKIOAj4LPCaYa5pROkZXnubTrGl7bqCbPdbgg90v72NPHefxrHL61/JuAdXsN/Gdqaxib9ffR3w+PSOlo52Hut2+bx/XPMz1k9rpeXgg2t6PYPRdUOZgbxvAzWQqSMAz9t1YKP2A93/YG5ws7pjw4BupDPQsN/SDBs21V6PwV2SNNKN1GD9IuA6gMz8TUQcMMz1DIneRn+ndjy6+a6CT7g5SreQusvrX0nrxs4njA73tt+e23UF2d2PO4b9Nq7rc789j/20xzaycePqon0vI8/dTzZs6Whn/U038tiDa0fEXGl4/IYyfb2+3kbfd3iwnT3HjqlbEK+3gY6gQzGKPhCD+TJx298eqrl9vYP7QNvDwMN+vf8KMND9++WmegP9DDzZWRpdmjo7O4e7hieJiK8AV2bmteXzvwF7ZGav/7datGjR/cDSISxRkiRJ26bd5syZs0NvK0bqiPUjwORuz5v7CtUAfb04SZIkaaiM1BvELASOAijnWN8xvOVIkiRJ/RupI9Y/AF4WEb8GmoAThrkeSZIkqV8jco61JEmS1GhG6lQQSZIkqaEYrCVJkqQKjNQ51iOWd4VURIwFLgV2B8YDZwN/Ai4DOoHFwEmZuSkiPgG8EtgAzMvMW4ajZg2diHgqsAh4GcXnfhn2i21aRHwUeDUwjuL3xy+wX2zTyt8jX6f4PbIReBf+/2JUcMR64DbfFRI4leKukNq2HAeszMxDgCOBLwDnAaeXy5qA10TE/sChwIHAscCFw1Svhkj5y/LLwNpykf1iGxcRhwEHA/9E8bnvgv1CxZXPWjLzYOAs4FPYL0YFg/XAPeGukMA2cVdIPcH3gY93e74BmEMxCgVwLXA4RV+5PjM7M/NvQEtEeM310e1c4EvAveVz+4WOoLhk7A+Aq4FrsF8IllB8xs3AdsB67BejgsF64LYDHu72fGNEOKVmG5KZj2bm6oiYDFwBnA40ZWbXJXZWA1N4cl/pWq5RKCLeBtyfmT/ptth+oRkUAzBvBE4Evklx0zP7xbbtUYppIHcClwAX4P8vRgWD9cAN6K6QGp0iYhfgJuDyzPwWsKnb6snAQzy5r3Qt1+j0dorr7/8ceC7wDeCp3dbbL7ZNK4GfZOa6zEygnScGI/vFtumDFP1iL4pztr5OMQe/i/2iQRmsB867Qm7jImJH4HrglMy8tFx8WzmXEop51wso+soREdEcEbtSfAl7YMgL1pDIzLmZeWhmHgbcDrwFuNZ+sc37FfCKiGiKiKcBTwF+Zr/Y5q3i8ZHoB4Gx+HtkVHAKw8B5V0h9DJgKfDwiuuZafwC4ICLGAW3AFZm5MSIWADdTfIk9aViq1XD6MHCJ/WLblZnXRMRc4BYe/7zvwX6xrTsfuLT8zMdR/F65FftFw/POi5IkSVIFnAoiSZIkVcBgLUmSJFXAYC1JkiRVwGAtSZIkVcBgLUmSJFXAYC1JI1RETIiIdw5wm9eW10vua/2ZEXHi1lcHETEtIt5cPr4sIl5RxX4lqVEZrCVp5JoJDChYU1xTfbs61NKb/YBXD9GxJGnE8wYxkjRynQbsHRGfAJ4NTC+Xv5/itsY3AnOB2cC/A+dS3k49Il6Umev623lEfKbcvhk4LzO/X96S/XZgX4qA/sbMXFreDOm1wP3ARODjZX3PiYh3l7t8T0ScTHHL7n/NzFsqeA8kqWE4Yi1JI9engD9RBNmfZeaLgXcDX8zMvwMnA1+nuIvbmzLzvyhvp15DqD4SmJWZ/wS8GDgtIrYvV9+SmYcDPwXeFBHPobjF8vOBY4CdutV3Y2ZeXD5flJkvAf4DeNtWv3pJajCOWEvSyPds4CUR8S/l86nlvz+kCLc3ZOayQexzTjlCDTAW2K18fFv5798ppqPMpgjbG4G1EXFrH/tcVP67guLLgCRtUxyxlqSRaxPF/6fvBM7PzMOAfwa+Wa7/MHA9cEBEHNRjmy25E7ip3OdLgO8BfynXdfZo+0fg+RHRHBHjgef1caye20nSNsVgLUkj133AOGAy8M/l6PJ1wOKIOAB4M3AK8A7g0oiYAvyaYo71tC3s+2rg0YhYQDHS3JmZq3trmJl3AD8GfgP8AFhf/twNPDsi5m3Vq5SkUaKps9MBBklS3yLiqcAbMvOicsT6j8BLMvNvw1yaJI0ozrGWpFEoIq4Ceo5aP5yZrxnE7h6gmAryPxTTPb5iqJakJ3PEWpIkSaqAc6wlSZKkChisJUmSpAoYrCVJkqQKGKwlSZKkChisJUmSpAoYrCVJkqQK/H9npgwtU++VdwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution Plot of lenghts\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "sns.distplot(a=sms[sms['label']=='ham']['text_length'], kde=False, hist=True, bins=50, label='Ham Sms')\n",
    "sns.distplot(a=sms[sms['label']=='spam']['text_length'], kde=False, hist=True, bins=50, color='red', label='Spam Sms')\n",
    "plt.legend()\n",
    "plt.ylabel('Number of Messages')\n",
    "plt.title('Distribution of lengths for Ham and Spam SMS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we see in previous table, *ham* messages maximum length is 910. It could be outliers so let's take a look on it, remove it and plot the distributions again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"For me the love should start with attraction.i should feel that I need her every time around me.she should be the first thing which comes in my thoughts.I would start the day and end it with her.she should be there every time I dream.love will be then when my every breath has her name.my life should happen around her.my life will be named to her.I would cry for her.will give all my happiness and take all her sorrows.I will be ready to fight with anyone for her.I will be in love when I will be doing the craziest things for her.love will be when I don't have to proove anyone that my girl is the most beautiful lady on the whole planet.I will always be singing praises for her.love will be when I start up making chicken curry and end up makiing sambar.life will be the most beautiful then.will get every morning and thank god for the day because she is with me.I would like to say a lot..will tell later..\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.loc[sms['text_length'] == 910]['text'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution Plot of lenghts\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "sns.distplot(a=sms.drop(axis=0, index=1085)[sms.drop(axis=0, index=1085)['label']=='ham']['text_length'], \\\n",
    "             kde=False, hist=True, color='blue', label='Ham Sms')\n",
    "\n",
    "sns.distplot(a=sms.drop(axis=0, index=1085)[sms.drop(axis=0, index=1085)['label']=='spam']['text_length'], \\\n",
    "             kde=False, hist=True, color='red', label='Spam Sms')\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel('Number of Messages')\n",
    "plt.title('Distribution of lengths for Ham and Spam SMS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5234270414993306"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Portion of spam messages that have 133<=length<=157\n",
    "sms.loc[(sms['label'] == 'spam') & (sms['text_length'] >= 133) & \\\n",
    "        (sms['text_length'] <=157)]['label'].count() \\\n",
    "        /sms.loc[(sms['label'] == 'spam')]['label'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0766839378238342"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Portion of ham messages that have 133<=length<=157\n",
    "sms.loc[(sms['label'] == 'ham') & (sms['text_length'] >= 133) & \\\n",
    "        (sms['text_length'] <=157)]['label'].count() \\\n",
    "        /sms.loc[(sms['label'] == 'ham')]['label'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Insights of the distributions and the statistical analysis:\n",
    "- The distribution of the spam messages has a smaller standard deviation and the mean value is much higher than the mean value of ham messages,\n",
    "- Almost 50% of the spam messages has length from 133 to 157, on the other hand 75% of the ham messages have a length lower or equal to 93\n",
    "\n",
    ">These insights could help us answer the first question. We could say that there is a hidden pattern to classify a message as spam or ham from its length. We could not be sure 100% but there is a big chance to classified it as a spam and be right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words model\n",
    "\n",
    "Machine learning models needs to ingest data in a structured form, a matrix where the rows represents observations and the columns are features/attributes. When working with text data, we need a method to convert this unstructured data into a form that the machine learning model can work with. One technique to transform text data into a matrix is to count the number of appearances of each word in each document. This technique is called the **bag of words model**. The model gets its name because each document is viewed as a bag holding all the words, disregarding word order, context, and grammar. After applying the bag of words model to a corpus, the resulting matrix will exhibit patterns that a machine learning model can exploit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The CountVectorizer transformer\n",
    "\n",
    "The bag of words model is found in scikit-learn with the *CountVectorizer* transformer. Note, scikit-learn uses the word **Vectorizer** to refer to transformers that convert a data structure (like a dictionary) into a NumPy array. Since it is a transformer, we need to first fit the object and then call transform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming and lemmatization\n",
    "\n",
    "**Stemming** is the process of reducing a word to its stem. Note, the stemming process is not 100% effective and sometimes the resulting stem is not an actual word. For example, the popular Porter stemming algorithm applied to \"argues\" and \"arguing\" returns `\"argu\"`.\n",
    "\n",
    "**Lemmatization** is the process of reducing a word to its lemma, or the dictionary form of the word. It is a more sophisticated process than stemming as it considers context and part of speech. Further, the resulting lemma is an actual word. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We are going to choose `lemmatization` for our process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Helper function to tokenize the messages\n",
    "    INPUT:\n",
    "    text: Messages\n",
    "    OUTPUT:\n",
    "    Tokens of word\n",
    "    \"\"\"\n",
    "\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to answer the second question\n",
    "\n",
    "> Which are the most common and most significant words for ham and spam messages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = CountVectorizer(tokenizer=tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>zouk</td>\n",
       "      <td>2669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>zoe</td>\n",
       "      <td>2668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>zed</td>\n",
       "      <td>2667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2563</th>\n",
       "      <td>zebra</td>\n",
       "      <td>2666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>yr</td>\n",
       "      <td>2665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>yourinclusive</td>\n",
       "      <td>2664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>yo</td>\n",
       "      <td>2663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>ymca</td>\n",
       "      <td>2662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>yhl</td>\n",
       "      <td>2661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>yet</td>\n",
       "      <td>2660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>yesterday</td>\n",
       "      <td>2659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>yes</td>\n",
       "      <td>2658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>yer</td>\n",
       "      <td>2657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>year</td>\n",
       "      <td>2656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>yeah</td>\n",
       "      <td>2655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word  counts\n",
       "749            zouk    2669\n",
       "1102            zoe    2668\n",
       "949             zed    2667\n",
       "2563          zebra    2666\n",
       "325              yr    2665\n",
       "930   yourinclusive    2664\n",
       "1592             yo    2663\n",
       "1881           ymca    2662\n",
       "1913            yhl    2661\n",
       "1915            yet    2660\n",
       "1173      yesterday    2659\n",
       "137             yes    2658\n",
       "1626            yer    2657\n",
       "164            year    2656\n",
       "671            yeah    2655"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The most common words in spam messages\n",
    "\n",
    "spam_word_counts = bag_of_words.fit_transform(sms.loc[sms['label']=='spam']['text'].values);\n",
    "\n",
    "spam_words = bag_of_words.vocabulary_\n",
    "\n",
    "spam_words_df = pd.DataFrame.from_dict(spam_words, orient='index')\n",
    "spam_words_df.reset_index(inplace=True)\n",
    "spam_words_df.columns = ['word', 'counts']\n",
    "\n",
    "spam_words_df.sort_values(by='counts', ascending=False, inplace=True)\n",
    "spam_words_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>zyada</td>\n",
       "      <td>6350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5263</th>\n",
       "      <td>zoom</td>\n",
       "      <td>6349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3901</th>\n",
       "      <td>zogtorius</td>\n",
       "      <td>6348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341</th>\n",
       "      <td>zoe</td>\n",
       "      <td>6347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3880</th>\n",
       "      <td>zindgi</td>\n",
       "      <td>6346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3455</th>\n",
       "      <td>zhong</td>\n",
       "      <td>6345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6115</th>\n",
       "      <td>zero</td>\n",
       "      <td>6344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5634</th>\n",
       "      <td>zealand</td>\n",
       "      <td>6343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>zaher</td>\n",
       "      <td>6342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5098</th>\n",
       "      <td>zac</td>\n",
       "      <td>6341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>z</td>\n",
       "      <td>6340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>yupz</td>\n",
       "      <td>6339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>yup</td>\n",
       "      <td>6338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5244</th>\n",
       "      <td>yuou</td>\n",
       "      <td>6337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3011</th>\n",
       "      <td>yuo</td>\n",
       "      <td>6336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  counts\n",
       "3874      zyada    6350\n",
       "5263       zoom    6349\n",
       "3901  zogtorius    6348\n",
       "2341        zoe    6347\n",
       "3880     zindgi    6346\n",
       "3455      zhong    6345\n",
       "6115       zero    6344\n",
       "5634    zealand    6343\n",
       "2147      zaher    6342\n",
       "5098        zac    6341\n",
       "1155          z    6340\n",
       "4283       yupz    6339\n",
       "184         yup    6338\n",
       "5244       yuou    6337\n",
       "3011        yuo    6336"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The most common words in ham messages\n",
    "\n",
    "ham_word_counts = bag_of_words.fit_transform(sms.loc[sms['label']=='ham']['text'].values)\n",
    "\n",
    "ham_words = bag_of_words.vocabulary_\n",
    "\n",
    "ham_words_df = pd.DataFrame.from_dict(ham_words, orient='index')\n",
    "ham_words_df.reset_index(inplace=True)\n",
    "ham_words_df.columns = ['word', 'counts']\n",
    "\n",
    "ham_words_df.sort_values(by='counts', ascending=False, inplace=True)\n",
    "ham_words_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term frequency-inverse document frequency\n",
    "\n",
    "The `CountVectorizer` creates a feature matrix of raw counts. Using raw counts has two problems, documents vary widely in length and the counts will be large for common words such as \"the\" and \"is\". We need to use a weighting scheme that considers the aforementioned attributes. The term frequency-inverse document frequency, **tf-idf** for short, is a popular weighting scheme to improve the simple count based data from the bag of words model. It is the product of two values, the term frequency and the inverse document frequency. There are several variants but the most popular is defined below.\n",
    "\n",
    "* **Term Frequency:**\n",
    "$$ \\mathrm{tf}(t, d) = \\frac{\\mathrm{counts}(t, d)}{\\sqrt{\\sum_{t \\in d} \\mathrm{counts}(t, d)^2}}, $$\n",
    "    where $\\mathrm{counts}(t, d)$ is the raw count of term $t$ in document $d$ and $t \\in d$ are the terms in document $d$. The normalization results in a vector of unit length.\n",
    "\n",
    "* **Inverse Document Frequency:**\n",
    "$$ \\mathrm{idf}(t, D) = \\ln\\left(\\frac{\\text{number of documents in corpus } D}{1 + \\text{number of documents with term } t}\\right). $$\n",
    "    Every counted term $t$ in the corpus will have its own idf weight. The $1+$ in the denominator is to ensure no division by zero if a term does not appear in the corpus. The idf weight is simply the log of the inverse of a term's document frequency.\n",
    "    \n",
    "With both $\\mathrm{tf}(t, d)$ and $\\mathrm{idf}(t, D)$ calculated, the tf-idf weight is\n",
    "\n",
    "$$ \\mathrm{tfidf}(t, d, D) = \\mathrm{tf}(t, d) \\mathrm{idf}(t, D).$$\n",
    "\n",
    "With the idf weighting, words that are very common throughout the documents get weighted down. The reverse is true; the count of rare words get weighted up. With the tf-idf weighting scheme, a machine learning model will have an easier time to learn patterns to properly predict labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer(smooth_idf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most significant words for spam messages are:\n",
      "6.924255797414532 howard\n",
      "6.924255797414532 cleared\n",
      "6.924255797414532 cine\n",
      "6.924255797414532 citizen\n",
      "6.924255797414532 cl\n",
      "6.924255797414532 claire\n",
      "6.924255797414532 clarification\n",
      "6.924255797414532 class\n",
      "6.924255797414532 classmate\n",
      "6.924255797414532 claypot\n",
      "6.924255797414532 cld\n",
      "6.924255797414532 cleaning\n",
      "6.924255797414532 clear\n",
      "6.924255797414532 clearer\n",
      "6.924255797414532 christ\n",
      "6.924255797414532 clearing\n",
      "6.924255797414532 clearly\n",
      "6.924255797414532 clever\n",
      "6.924255797414532 cliff\n"
     ]
    }
   ],
   "source": [
    "# Most significant words in spam messages\n",
    "\n",
    "spam_word_weights = tfidf.fit_transform(spam_word_counts)\n",
    "top_idf_indices = tfidf.idf_.argsort()[:-20:-1]\n",
    "ind_to_word = bag_of_words.get_feature_names()\n",
    "\n",
    "print('The most significant words for spam messages are:')\n",
    "for ind in top_idf_indices:\n",
    "    print(tfidf.idf_[ind], ind_to_word[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most significant words for ham messages are:\n",
      "8.788626065625031 zyada\n",
      "8.788626065625031 iknow\n",
      "8.788626065625031 ifink\n",
      "8.788626065625031 ignorant\n",
      "8.788626065625031 ignoring\n",
      "8.788626065625031 ihave\n",
      "8.788626065625031 ijust\n",
      "8.788626065625031 ikno\n",
      "8.788626065625031 ileave\n",
      "8.788626065625031 immunisation\n",
      "8.788626065625031 illspeak\n",
      "8.788626065625031 ilol\n",
      "8.788626065625031 imagination\n",
      "8.788626065625031 imat\n",
      "8.788626065625031 imf\n",
      "8.788626065625031 imin\n",
      "8.788626065625031 iff\n",
      "8.788626065625031 ie\n",
      "8.788626065625031 idu\n"
     ]
    }
   ],
   "source": [
    "# Most significant words in ham messages\n",
    "\n",
    "ham_word_weights = tfidf.fit_transform(ham_word_counts)\n",
    "top_idf_indices = tfidf.idf_.argsort()[:-20:-1]\n",
    "ind_to_word = bag_of_words.get_feature_names()\n",
    "\n",
    "print('The most significant words for ham messages are:')\n",
    "for ind in top_idf_indices:\n",
    "    print(tfidf.idf_[ind], ind_to_word[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sms.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sms.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MyPc\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('bagOfWords',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function toke...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bagOfWords', bag_of_words),\n",
    "    ('tfidf', tfidf),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(cv, y_test, y_pred):\n",
    "    labels = np.unique(y_pred)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "    accuracy = (y_pred == y_test).mean()\n",
    "\n",
    "    print(\"Labels:\", labels)\n",
    "    print(\"Confusion Matrix:\\n\", confusion_mat)\n",
    "    print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['ham' 'spam']\n",
      "Confusion Matrix:\n",
      " [[1207    1]\n",
      " [  30  155]]\n",
      "Accuracy: 0.9777458722182341\n"
     ]
    }
   ],
   "source": [
    "display_results(pipeline, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Nice one with the first model. We will try to improve it using GridSearchCv and tuning its parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tune Parameters with GridSearchCv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('bagOfWords',\n",
       "   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                   dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                   lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                   ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                   strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                   tokenizer=<function tokenize at 0x000002291D549D90>,\n",
       "                   vocabulary=None)),\n",
       "  ('tfidf',\n",
       "   TfidfTransformer(norm='l2', smooth_idf=False, sublinear_tf=False, use_idf=True)),\n",
       "  ('clf',\n",
       "   RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                          max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                          n_jobs=None, oob_score=False, random_state=None,\n",
       "                          verbose=0, warm_start=False))],\n",
       " 'verbose': False,\n",
       " 'bagOfWords': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                 dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                 lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                 ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                 strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                 tokenizer=<function tokenize at 0x000002291D549D90>,\n",
       "                 vocabulary=None),\n",
       " 'tfidf': TfidfTransformer(norm='l2', smooth_idf=False, sublinear_tf=False, use_idf=True),\n",
       " 'clf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                        max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                        n_jobs=None, oob_score=False, random_state=None,\n",
       "                        verbose=0, warm_start=False),\n",
       " 'bagOfWords__analyzer': 'word',\n",
       " 'bagOfWords__binary': False,\n",
       " 'bagOfWords__decode_error': 'strict',\n",
       " 'bagOfWords__dtype': numpy.int64,\n",
       " 'bagOfWords__encoding': 'utf-8',\n",
       " 'bagOfWords__input': 'content',\n",
       " 'bagOfWords__lowercase': True,\n",
       " 'bagOfWords__max_df': 1.0,\n",
       " 'bagOfWords__max_features': None,\n",
       " 'bagOfWords__min_df': 1,\n",
       " 'bagOfWords__ngram_range': (1, 1),\n",
       " 'bagOfWords__preprocessor': None,\n",
       " 'bagOfWords__stop_words': None,\n",
       " 'bagOfWords__strip_accents': None,\n",
       " 'bagOfWords__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'bagOfWords__tokenizer': <function __main__.tokenize(text)>,\n",
       " 'bagOfWords__vocabulary': None,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': False,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'clf__bootstrap': True,\n",
       " 'clf__class_weight': None,\n",
       " 'clf__criterion': 'gini',\n",
       " 'clf__max_depth': None,\n",
       " 'clf__max_features': 'auto',\n",
       " 'clf__max_leaf_nodes': None,\n",
       " 'clf__min_impurity_decrease': 0.0,\n",
       " 'clf__min_impurity_split': None,\n",
       " 'clf__min_samples_leaf': 1,\n",
       " 'clf__min_samples_split': 2,\n",
       " 'clf__min_weight_fraction_leaf': 0.0,\n",
       " 'clf__n_estimators': 10,\n",
       " 'clf__n_jobs': None,\n",
       " 'clf__oob_score': False,\n",
       " 'clf__random_state': None,\n",
       " 'clf__verbose': 0,\n",
       " 'clf__warm_start': False}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'bagOfWords__ngram_range': ((1, 1), (1, 2)),\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__min_samples_leaf': [1,3,5],\n",
    "    'clf__n_estimators': [10, 30, 50],\n",
    "    'clf__min_samples_split': [2, 3, 4]\n",
    "}\n",
    "\n",
    "clf_pipeline = GridSearchCV(pipeline, param_grid=parameters, n_jobs=-1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MyPc\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 324 out of 324 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('bagOfWords',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accen...\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'bagOfWords__ngram_range': ((1, 1), (1, 2)),\n",
       "                         'clf__min_samples_leaf': [1, 3, 5],\n",
       "                         'clf__min_samples_split': [2, 3, 4],\n",
       "                         'clf__n_estimators': [10, 30, 50],\n",
       "                         'tfidf__use_idf': (True, False)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['ham' 'spam']\n",
      "Confusion Matrix:\n",
      " [[1207    1]\n",
      " [  24  161]]\n",
      "Accuracy: 0.9820531227566404\n"
     ]
    }
   ],
   "source": [
    "display_results(clf_pipeline, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent!!! We have an improvement from the first model. Now we are going to work with a second model, a `Stochastic Gradient Descent` classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('bagOfWords',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function toke...\n",
       "                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "                               early_stopping=False, epsilon=0.1, eta0=0.0,\n",
       "                               fit_intercept=True, l1_ratio=0.15,\n",
       "                               learning_rate='optimal', loss='hinge',\n",
       "                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "                               penalty='l2', power_t=0.5, random_state=None,\n",
       "                               shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "                               verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bagOfWords', bag_of_words),\n",
    "    ('tfidf', tfidf),\n",
    "    ('sgd', sgd)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['ham' 'spam']\n",
      "Confusion Matrix:\n",
      " [[1205    3]\n",
      " [  13  172]]\n",
      "Accuracy: 0.9885139985642498\n"
     ]
    }
   ],
   "source": [
    "display_results(pipeline, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Tune the parameters of SGD classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('bagOfWords',\n",
       "   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                   dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                   lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                   ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                   strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                   tokenizer=<function tokenize at 0x000002291D549D90>,\n",
       "                   vocabulary=None)),\n",
       "  ('tfidf',\n",
       "   TfidfTransformer(norm='l2', smooth_idf=False, sublinear_tf=False, use_idf=True)),\n",
       "  ('sgd', SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "                 early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "                 l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "                 max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "                 power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "                 validation_fraction=0.1, verbose=0, warm_start=False))],\n",
       " 'verbose': False,\n",
       " 'bagOfWords': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                 dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                 lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                 ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                 strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                 tokenizer=<function tokenize at 0x000002291D549D90>,\n",
       "                 vocabulary=None),\n",
       " 'tfidf': TfidfTransformer(norm='l2', smooth_idf=False, sublinear_tf=False, use_idf=True),\n",
       " 'sgd': SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "               early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "               l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "               max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "               power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "               validation_fraction=0.1, verbose=0, warm_start=False),\n",
       " 'bagOfWords__analyzer': 'word',\n",
       " 'bagOfWords__binary': False,\n",
       " 'bagOfWords__decode_error': 'strict',\n",
       " 'bagOfWords__dtype': numpy.int64,\n",
       " 'bagOfWords__encoding': 'utf-8',\n",
       " 'bagOfWords__input': 'content',\n",
       " 'bagOfWords__lowercase': True,\n",
       " 'bagOfWords__max_df': 1.0,\n",
       " 'bagOfWords__max_features': None,\n",
       " 'bagOfWords__min_df': 1,\n",
       " 'bagOfWords__ngram_range': (1, 1),\n",
       " 'bagOfWords__preprocessor': None,\n",
       " 'bagOfWords__stop_words': None,\n",
       " 'bagOfWords__strip_accents': None,\n",
       " 'bagOfWords__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'bagOfWords__tokenizer': <function __main__.tokenize(text)>,\n",
       " 'bagOfWords__vocabulary': None,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': False,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'sgd__alpha': 0.0001,\n",
       " 'sgd__average': False,\n",
       " 'sgd__class_weight': None,\n",
       " 'sgd__early_stopping': False,\n",
       " 'sgd__epsilon': 0.1,\n",
       " 'sgd__eta0': 0.0,\n",
       " 'sgd__fit_intercept': True,\n",
       " 'sgd__l1_ratio': 0.15,\n",
       " 'sgd__learning_rate': 'optimal',\n",
       " 'sgd__loss': 'hinge',\n",
       " 'sgd__max_iter': 1000,\n",
       " 'sgd__n_iter_no_change': 5,\n",
       " 'sgd__n_jobs': None,\n",
       " 'sgd__penalty': 'l2',\n",
       " 'sgd__power_t': 0.5,\n",
       " 'sgd__random_state': None,\n",
       " 'sgd__shuffle': True,\n",
       " 'sgd__tol': 0.001,\n",
       " 'sgd__validation_fraction': 0.1,\n",
       " 'sgd__verbose': 0,\n",
       " 'sgd__warm_start': False}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'bagOfWords__ngram_range': ((1, 1), (1, 2)),\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'sgd__alpha': [0.0001, 0.0003, 0.0009, 0.001, 0.003, 0.009],\n",
    "    'sgd__max_iter': [1000, 3000, 9000],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MyPc\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 216 out of 216 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('bagOfWords',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accen...\n",
       "                                                      shuffle=True, tol=0.001,\n",
       "                                                      validation_fraction=0.1,\n",
       "                                                      verbose=0,\n",
       "                                                      warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'bagOfWords__ngram_range': ((1, 1), (1, 2)),\n",
       "                         'sgd__alpha': [0.0001, 0.0003, 0.0009, 0.001, 0.003,\n",
       "                                        0.009],\n",
       "                         'sgd__max_iter': [1000, 3000, 9000],\n",
       "                         'tfidf__use_idf': (True, False)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_pipeline = GridSearchCV(pipeline, param_grid=parameters, n_jobs=-1, verbose=2)\n",
    "\n",
    "sgd_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sgd_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['ham' 'spam']\n",
      "Confusion Matrix:\n",
      " [[1205    3]\n",
      " [   9  176]]\n",
      "Accuracy: 0.9913854989231874\n"
     ]
    }
   ],
   "source": [
    "display_results(sgd_pipeline, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "1. We uncover hidden patterns by using the length of the messages. It is not a good metric of course but it could be a first check to recognize a spam or ham message.\n",
    "\n",
    "2. We find the most common words for each category. But as long as `most common` doesn't mean the most significant we also find the most significants words for each category.\n",
    "\n",
    "3. We trained two models. A [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) and a [SGDClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier). Both did very good with predictions but SGD did a bit better. \n",
    "\n",
    "    We also tuned their parameters and we successfully improved their accuracies. One way we could improve our model it might be to create a function to extact all the verbs for each message and using feature union to combine the results table and work on them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
